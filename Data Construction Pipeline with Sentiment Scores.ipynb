{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the annuals.PY file (This contains some PDF-to-text() and the text_cleaning() functions)\n",
    "import annuals as an\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to the directory containing the folder \"Banks\".\n",
    "#The Banks folder contains multiple subfolders with the names of the Banks, e.g. Dhanalakshmi, Lakshmi Vilas \n",
    "#Each Subfolder contains 2 subfolders, viz, \"Auditor Report\" & \"Director Report\".\n",
    "\n",
    "os.chdir(r\"C:\\Users\\goura\\Documents\\000. Research\\Catching the sentiments of the Annual Reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Scores using the Harvard-IV Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path should contain \"\\\\\" intead of \"\\\" or \"/\"\n",
    "import pysentiment2 as ps\n",
    "\n",
    "def sentiscore_harvard(path, bank_name, report):\n",
    "    \"\"\"\n",
    "    path = The path of the \"Banks\" folder\n",
    "    bank_name = Name of the Bank of interest (same as its folder name)\n",
    "    report = \"Auditor Report\" or \"Director Report\"\n",
    "    \"\"\"\n",
    "    \n",
    "    #This sets the link to the folder containing the reports in PDF\n",
    "    link = path + \"\\\\\" + bank_name + \"\\\\\" + report\n",
    "    os.chdir(link)\n",
    "    \n",
    "    #Initialing a dictionary with empty list as values. This will be later converted to a data frame\n",
    "    read_scores = {\"Year\": [], \"Length\": [], \"NPositive\": [], \"NNegative\": [], \"PPositive\": [], \"PNegative\": [], \"Polarity\": [], \"Subjectivity\": []}\n",
    "\n",
    "    for file in os.listdir():\n",
    "        if \".pdf\" in file:\n",
    "            document = an.PDF2text(file)\n",
    "            cleaned_file = an.cleaning_pipeline(document)\n",
    "            hiv4 = ps.HIV4()\n",
    "            tokens = hiv4.tokenize(cleaned_file)\n",
    "            score = hiv4.get_score(tokens)\n",
    "\n",
    "            if len(cleaned_file) != 0:\n",
    "                #Readibility scores\n",
    "                read_scores[\"Length\"].append(len(tokens))\n",
    "                read_scores[\"NPositive\"].append(score['Positive'])\n",
    "                read_scores[\"NNegative\"].append(score['Negative'])\n",
    "                read_scores[\"PPositive\"].append(round(score['Positive']/len(tokens),4))\n",
    "                read_scores[\"PNegative\"].append(round(score['Negative']/len(tokens),4))\n",
    "                read_scores[\"Polarity\"].append(round(score['Polarity'],4))\n",
    "                read_scores[\"Subjectivity\"].append(round(score['Subjectivity'],4))\n",
    "                #Year\n",
    "                read_scores[\"Year\"].append(int(file[file.find(\"_\")+1:file.find(\"-\")]))\n",
    "            else:\n",
    "                read_scores[\"Length\"].append(np.NaN)\n",
    "                read_scores[\"NPositive\"].append(np.NaN)\n",
    "                read_scores[\"NNegative\"].append(np.NaN)\n",
    "                read_scores[\"PPositive\"].append(np.NaN)\n",
    "                read_scores[\"PNegative\"].append(np.NaN)\n",
    "                read_scores[\"Polarity\"].append(np.NaN)\n",
    "                read_scores[\"Subjectivity\"].append(np.NaN)  \n",
    "                read_scores[\"Year\"].append(int(file[file.find(\"_\")+1:file.find(\"-\")]))\n",
    "            print(file)\n",
    "    \n",
    "    #Converting the read_scores dictionary to a dataframe\n",
    "    df = pd.DataFrame(read_scores)\n",
    "    df[\"Bank\"] = bank_name\n",
    "    df[\"Report\"] = report\n",
    "    df[\"Dictionary\"] = \"Harvard-IV\"\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Scores using the Loughran & McDonald's Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path should contain \"\\\\\" intead of \"\\\" or \"/\"\n",
    "import pysentiment2 as ps\n",
    "\n",
    "def sentiscore_Loughran(path, bank_name, report):\n",
    "    link = path + \"\\\\\" + bank_name + \"\\\\\" + report\n",
    "    os.chdir(link)\n",
    "    read_scores = {\"Year\": [], \"Length\": [], \"NPositive\": [], \"NNegative\": [], \"PPositive\": [], \"PNegative\": [], \"Polarity\": [], \"Subjectivity\": []}\n",
    "\n",
    "    for file in os.listdir():\n",
    "        if \".pdf\" in file:\n",
    "            document = an.PDF2text(file)\n",
    "            cleaned_file = an.cleaning_pipeline(document)\n",
    "            hiv4 = lm = ps.LM()\n",
    "            tokens = hiv4.tokenize(cleaned_file)\n",
    "            score = hiv4.get_score(tokens)\n",
    "\n",
    "            if len(cleaned_file) != 0:\n",
    "                #Readibility scores\n",
    "                read_scores[\"Length\"].append(len(tokens))\n",
    "                read_scores[\"NPositive\"].append(score['Positive'])\n",
    "                read_scores[\"NNegative\"].append(score['Negative'])\n",
    "                read_scores[\"PPositive\"].append(round(score['Positive']/len(tokens),4))\n",
    "                read_scores[\"PNegative\"].append(round(score['Negative']/len(tokens),4))\n",
    "                read_scores[\"Polarity\"].append(round(score['Polarity'],4))\n",
    "                read_scores[\"Subjectivity\"].append(round(score['Subjectivity'],4))\n",
    "                #Year\n",
    "                read_scores[\"Year\"].append(int(file[file.find(\"_\")+1:file.find(\"-\")]))\n",
    "            else:\n",
    "                read_scores[\"Length\"].append(np.NaN)\n",
    "                read_scores[\"NPositive\"].append(np.NaN)\n",
    "                read_scores[\"NNegative\"].append(np.NaN)\n",
    "                read_scores[\"PPositive\"].append(np.NaN)\n",
    "                read_scores[\"PNegative\"].append(np.NaN)\n",
    "                read_scores[\"Polarity\"].append(np.NaN)\n",
    "                read_scores[\"Subjectivity\"].append(np.NaN)  \n",
    "                read_scores[\"Year\"].append(int(file[file.find(\"_\")+1:file.find(\"-\")]))\n",
    "            print(file)\n",
    "            \n",
    "    df = pd.DataFrame(read_scores)\n",
    "    df[\"Bank\"] = bank_name\n",
    "    df[\"Report\"] = report\n",
    "    df[\"Dictionary\"] = \"Loughran & McDonald\"\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage of the sentiscore_harvard() function\n",
    "path = \"C:\\\\Users\\\\goura\\Documents\\\\000. Research\\\\Catching the sentiments of the Annual Reports\\\\Bank\"\n",
    "bank = \"Lakshmi Vilas\"\n",
    "choice = int(input(\"1 or 0: \"))\n",
    "if choice == 1:\n",
    "    report = \"Director Report\"\n",
    "else:\n",
    "    report = \"Auditor Report\"\n",
    "    \n",
    "sentiscore_harvard(path, bank, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
